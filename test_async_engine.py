#!/usr/bin/env python3
"""
æµ‹è¯• vLLM å¼‚æ­¥å¼•æ“å®ç°
"""

import asyncio
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

async def test_async_engine():
    """æµ‹è¯•å¼‚æ­¥å¼•æ“çš„åŸºæœ¬åŠŸèƒ½"""
    try:
        from vllm.engine.async_llm_engine import AsyncLLMEngine, AsyncEngineArgs
        
        print("âœ… AsyncLLMEngine å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•å¼•æ“å‚æ•°åˆ›å»º
        engine_args = AsyncEngineArgs(
            model="microsoft/DialoGPT-small",  # ä½¿ç”¨å°æ¨¡å‹è¿›è¡Œæµ‹è¯•
            max_model_len=512,
            enable_prefix_caching=True,
            gpu_memory_utilization=0.1,
            trust_remote_code=True,
            tensor_parallel_size=1,
        )
        print("âœ… AsyncEngineArgs åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å¼•æ“åˆå§‹åŒ–
        engine = AsyncLLMEngine.from_engine_args(engine_args)
        print("âœ… AsyncLLMEngine åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•å¼‚æ­¥ç”Ÿæˆ
        test_prompt = "Hello, how are you?"
        sampling_params = {
            "temperature": 0,
            "max_tokens": 10,
        }
        
        print("æµ‹è¯•å¼‚æ­¥ç”Ÿæˆ...")
        async for output in engine.generate(test_prompt, sampling_params):
            print(f"âœ… å¼‚æ­¥ç”ŸæˆæˆåŠŸ: {output.outputs[0].text}")
            break
        
        # å…³é—­å¼•æ“
        await engine.close()
        print("âœ… å¼•æ“å…³é—­æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_compatible_service():
    """æµ‹è¯•å…¼å®¹æ€§æœåŠ¡"""
    try:
        from rerank_service_compatible import initialize_model, ModelConfig
        
        print("\næµ‹è¯•å…¼å®¹æ€§æœåŠ¡...")
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        config = ModelConfig(
            model_path="microsoft/DialoGPT-small",
            model_size="0.1B",
            gpu_memory_utilization=0.1,
            max_model_len=512
        )
        
        # åˆå§‹åŒ–æ¨¡å‹
        await initialize_model(config)
        print("âœ… å…¼å®¹æ€§æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ å…¼å®¹æ€§æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("vLLM å¼‚æ­¥å¼•æ“æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å¼‚æ­¥å¼•æ“
    engine_ok = await test_async_engine()
    
    # æµ‹è¯•å…¼å®¹æ€§æœåŠ¡
    service_ok = await test_compatible_service()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœ")
    print("=" * 50)
    
    if engine_ok and service_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… å¯ä»¥ä½¿ç”¨ rerank_service_compatible.py")
        print("âœ… å¼‚æ­¥å¼•æ“å·¥ä½œæ­£å¸¸")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        
        if not engine_ok:
            print("  - å¼‚æ­¥å¼•æ“æµ‹è¯•å¤±è´¥")
        if not service_ok:
            print("  - å…¼å®¹æ€§æœåŠ¡æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    asyncio.run(main())
